{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load darknet.py\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import utils.network as net_utils\n",
    "import cfgs.config as cfg\n",
    "from layers.reorg.reorg_layer import ReorgLayer\n",
    "from utils.cython_bbox import bbox_ious, bbox_intersections, bbox_overlaps, anchor_intersections\n",
    "from utils.cython_yolo import yolo_to_bbox\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def _make_layers(in_channels, net_cfg):\n",
    "    layers = []\n",
    "\n",
    "    if len(net_cfg) > 0 and isinstance(net_cfg[0], list):\n",
    "        for sub_cfg in net_cfg:\n",
    "            layer, in_channels = _make_layers(in_channels, sub_cfg)\n",
    "            layers.append(layer)\n",
    "    else:\n",
    "        for item in net_cfg:\n",
    "            if item == 'M':\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                out_channels, ksize = item\n",
    "                layers.append(net_utils.Conv2d_BatchNorm(in_channels, out_channels, ksize, same_padding=True))\n",
    "                # layers.append(net_utils.Conv2d(in_channels, out_channels, ksize, same_padding=True))\n",
    "                in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(*layers), in_channels\n",
    "\n",
    "\n",
    "def _process_batch(data):\n",
    "    W, H = cfg.out_size\n",
    "    inp_size = cfg.inp_size\n",
    "    out_size = cfg.out_size\n",
    "\n",
    "    bbox_pred_np, gt_boxes, gt_classes, dontcares, iou_pred_np = data\n",
    "\n",
    "    # net output\n",
    "    hw, num_anchors, _ = bbox_pred_np.shape\n",
    "\n",
    "    # gt\n",
    "    _classes = np.zeros([hw, num_anchors, cfg.num_classes], dtype=np.float)\n",
    "    _class_mask = np.zeros([hw, num_anchors, 1], dtype=np.float)\n",
    "\n",
    "    _ious = np.zeros([hw, num_anchors, 1], dtype=np.float)\n",
    "    _iou_mask = np.zeros([hw, num_anchors, 1], dtype=np.float)\n",
    "\n",
    "    _boxes = np.zeros([hw, num_anchors, 4], dtype=np.float)\n",
    "    _boxes[:, :, 0:2] = 0.5\n",
    "    _boxes[:, :, 2:4] = 1.0\n",
    "    _box_mask = np.zeros([hw, num_anchors, 1], dtype=np.float) + 0.01\n",
    "\n",
    "    # scale pred_bbox\n",
    "    anchors = np.ascontiguousarray(cfg.anchors, dtype=np.float)\n",
    "    bbox_pred_np = np.expand_dims(bbox_pred_np, 0)\n",
    "    bbox_np = yolo_to_bbox(\n",
    "        np.ascontiguousarray(bbox_pred_np, dtype=np.float),\n",
    "        anchors,\n",
    "        H, W)\n",
    "    bbox_np = bbox_np[0]  # bbox_np = (hw, num_anchors, (x1, y1, x2, y2))   range: 0 ~ 1\n",
    "    bbox_np[:, :, 0::2] *= float(inp_size[0])  # rescale x\n",
    "    bbox_np[:, :, 1::2] *= float(inp_size[1])  # rescale y\n",
    "\n",
    "    # gt_boxes_b = np.asarray(gt_boxes[b], dtype=np.float)\n",
    "    gt_boxes_b = np.asarray(gt_boxes, dtype=np.float)\n",
    "\n",
    "    # for each cell, compare predicted_bbox and gt_bbox\n",
    "    bbox_np_b = np.reshape(bbox_np, [-1, 4])\n",
    "    ious = bbox_ious(\n",
    "        np.ascontiguousarray(bbox_np_b, dtype=np.float),\n",
    "        np.ascontiguousarray(gt_boxes_b, dtype=np.float)\n",
    "    )\n",
    "    best_ious = np.max(ious, axis=1).reshape(_iou_mask.shape)\n",
    "    iou_penalty = 0 - iou_pred_np[best_ious < cfg.iou_thresh]\n",
    "    _iou_mask[best_ious <= cfg.iou_thresh] = cfg.noobject_scale * iou_penalty\n",
    "\n",
    "    # locate the cell of each gt_boxe\n",
    "    cell_w = float(inp_size[0]) / W\n",
    "    cell_h = float(inp_size[1]) / H\n",
    "    cx = (gt_boxes_b[:, 0] + gt_boxes_b[:, 2]) * 0.5 / cell_w\n",
    "    cy = (gt_boxes_b[:, 1] + gt_boxes_b[:, 3]) * 0.5 / cell_h\n",
    "    cell_inds = np.floor(cy) * W + np.floor(cx)\n",
    "    cell_inds = cell_inds.astype(np.int)\n",
    "\n",
    "    target_boxes = np.empty(gt_boxes_b.shape, dtype=np.float)\n",
    "    target_boxes[:, 0] = cx - np.floor(cx)  # cx\n",
    "    target_boxes[:, 1] = cy - np.floor(cy)  # cy\n",
    "    target_boxes[:, 2] = (gt_boxes_b[:, 2] - gt_boxes_b[:, 0]) / inp_size[0] * out_size[0]  # tw\n",
    "    target_boxes[:, 3] = (gt_boxes_b[:, 3] - gt_boxes_b[:, 1]) / inp_size[1] * out_size[1]  # th\n",
    "\n",
    "    # for each gt boxes, match the best anchor\n",
    "    gt_boxes_resize = np.copy(gt_boxes_b)\n",
    "    gt_boxes_resize[:, 0::2] *= (out_size[0] / float(inp_size[0]))\n",
    "    gt_boxes_resize[:, 1::2] *= (out_size[1] / float(inp_size[1]))\n",
    "    anchor_ious = anchor_intersections(\n",
    "        anchors,\n",
    "        np.ascontiguousarray(gt_boxes_resize, dtype=np.float)\n",
    "    )\n",
    "    anchor_inds = np.argmax(anchor_ious, axis=0)\n",
    "\n",
    "    ious_reshaped = np.reshape(ious, [hw, num_anchors, len(cell_inds)])\n",
    "    for i, cell_ind in enumerate(cell_inds):\n",
    "        if cell_ind >= hw or cell_ind < 0:\n",
    "            print cell_ind\n",
    "            continue\n",
    "        a = anchor_inds[i]\n",
    "\n",
    "        iou_pred_cell_anchor = iou_pred_np[cell_ind, a, :]  # 0 ~ 1, should be close to 1\n",
    "        _iou_mask[cell_ind, a, :] = cfg.object_scale * (1 - iou_pred_cell_anchor)\n",
    "        # _ious[cell_ind, a, :] = anchor_ious[a, i]\n",
    "        _ious[cell_ind, a, :] = ious_reshaped[cell_ind, a, i]\n",
    "\n",
    "        _box_mask[cell_ind, a, :] = cfg.coord_scale\n",
    "        target_boxes[i, 2:4] /= anchors[a]\n",
    "        _boxes[cell_ind, a, :] = target_boxes[i]\n",
    "\n",
    "        _class_mask[cell_ind, a, :] = cfg.class_scale\n",
    "        _classes[cell_ind, a, gt_classes[i]] = 1.\n",
    "\n",
    "    # _boxes[:, :, 2:4] = np.maximum(_boxes[:, :, 2:4], 0.001)\n",
    "    # _boxes[:, :, 2:4] = np.log(_boxes[:, :, 2:4])\n",
    "\n",
    "    return _boxes, _ious, _classes, _box_mask, _iou_mask, _class_mask\n",
    "\n",
    "\n",
    "class Darknet19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Darknet19, self).__init__()\n",
    "\n",
    "        net_cfgs = [\n",
    "            # conv1s\n",
    "            [(32, 3)],\n",
    "            ['M', (64, 3)],\n",
    "            ['M', (128, 3), (64, 1), (128, 3)],\n",
    "            ['M', (256, 3), (128, 1), (256, 3)],\n",
    "            ['M', (512, 3), (256, 1), (512, 3), (256, 1), (512, 3)],\n",
    "            # conv2\n",
    "            ['M', (1024, 3), (512, 1), (1024, 3), (512, 1), (1024, 3)],\n",
    "            # ------------\n",
    "            # conv3\n",
    "            [(1024, 3), (1024, 3)],\n",
    "            # conv4\n",
    "            [(1024, 3)]\n",
    "        ]\n",
    "\n",
    "        # darknet\n",
    "        self.conv1s, c1 = _make_layers(3, net_cfgs[0:5])\n",
    "        self.conv2, c2 = _make_layers(c1, net_cfgs[5])\n",
    "        # ---\n",
    "        self.conv3, c3 = _make_layers(c2, net_cfgs[6])\n",
    "\n",
    "        stride = 2\n",
    "        self.reorg = ReorgLayer(stride=2)   # stride*stride times the channels of conv1s\n",
    "        # cat [conv1s, conv3]\n",
    "        self.conv4, c4 = _make_layers((c1*(stride*stride) + c3), net_cfgs[7])\n",
    "\n",
    "        # linear\n",
    "        out_channels = cfg.num_anchors * (cfg.num_classes + 5)\n",
    "        self.conv5 = net_utils.Conv2d(c4, out_channels, 1, 1, relu=False)\n",
    "\n",
    "        # train\n",
    "        self.bbox_loss = None\n",
    "        self.iou_loss = None\n",
    "        self.cls_loss = None\n",
    "        self.pool = Pool(processes=10)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.bbox_loss + self.iou_loss + self.cls_loss\n",
    "\n",
    "    def forward(self, im_data, gt_boxes=None, gt_classes=None, dontcare=None):\n",
    "        conv1s = self.conv1s(im_data)\n",
    "        conv2 = self.conv2(conv1s)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv1s_reorg = self.reorg(conv1s)\n",
    "        cat_1_3 = torch.cat([conv1s_reorg, conv3], 1)\n",
    "        conv4 = self.conv4(cat_1_3)\n",
    "        conv5 = self.conv5(conv4)   # batch_size, out_channels, h, w\n",
    "\n",
    "        # for detection\n",
    "        # bsize, c, h, w -> bsize, h, w, c -> bsize, h x w, num_anchors, 5+num_classes\n",
    "        bsize, _, h, w = conv5.size()\n",
    "        # assert bsize == 1, 'detection only support one image per batch'\n",
    "        conv5_reshaped = conv5.permute(0, 2, 3, 1).contiguous().view(bsize, -1, cfg.num_anchors, cfg.num_classes + 5)\n",
    "\n",
    "        # tx, ty, tw, th, to -> sig(tx), sig(ty), exp(tw), exp(th), sig(to)\n",
    "        xy_pred = F.sigmoid(conv5_reshaped[:, :, :, 0:2])\n",
    "        wh_pred = torch.exp(conv5_reshaped[:, :, :, 2:4])\n",
    "        bbox_pred = torch.cat([xy_pred, wh_pred], 3)\n",
    "        iou_pred = F.sigmoid(conv5_reshaped[:, :, :, 4:5])\n",
    "\n",
    "        score_pred = conv5_reshaped[:, :, :, 5:].contiguous()\n",
    "        prob_pred = F.softmax(score_pred.view(-1, score_pred.size()[-1])).view_as(score_pred)\n",
    "\n",
    "        # for training\n",
    "        if self.training:\n",
    "            bbox_pred_np = bbox_pred.data.cpu().numpy()\n",
    "            iou_pred_np = iou_pred.data.cpu().numpy()\n",
    "            _boxes, _ious, _classes, _box_mask, _iou_mask, _class_mask = self._build_target(\n",
    "                bbox_pred_np, gt_boxes, gt_classes, dontcare, iou_pred_np)\n",
    "\n",
    "            _boxes = net_utils.np_to_variable(_boxes)\n",
    "            _ious = net_utils.np_to_variable(_ious)\n",
    "            _classes = net_utils.np_to_variable(_classes)\n",
    "            box_mask = net_utils.np_to_variable(_box_mask, dtype=torch.FloatTensor)\n",
    "            iou_mask = net_utils.np_to_variable(_iou_mask, dtype=torch.FloatTensor)\n",
    "            class_mask = net_utils.np_to_variable(_class_mask, dtype=torch.FloatTensor)\n",
    "\n",
    "            num_boxes = sum((len(boxes) for boxes in gt_boxes))\n",
    "\n",
    "            # _boxes[:, :, :, 2:4] = torch.log(_boxes[:, :, :, 2:4])\n",
    "            box_mask = box_mask.expand_as(_boxes)\n",
    "\n",
    "            self.bbox_loss = nn.MSELoss(size_average=False)(bbox_pred * box_mask, _boxes * box_mask) / num_boxes\n",
    "            self.iou_loss = nn.MSELoss(size_average=False)(iou_pred * iou_mask, _ious * iou_mask) / num_boxes\n",
    "\n",
    "            class_mask = class_mask.expand_as(prob_pred)\n",
    "            self.cls_loss = nn.MSELoss(size_average=False)(prob_pred * class_mask, _classes * class_mask) / num_boxes\n",
    "\n",
    "        return bbox_pred, iou_pred, prob_pred\n",
    "\n",
    "    def _build_target(self, bbox_pred_np, gt_boxes, gt_classes, dontcare, iou_pred_np):\n",
    "        \"\"\"\n",
    "        :param bbox_pred: shape: (bsize, h x w, num_anchors, 4) : (sig(tx), sig(ty), exp(tw), exp(th))\n",
    "        \"\"\"\n",
    "\n",
    "        bsize = bbox_pred_np.shape[0]\n",
    "\n",
    "        targets = self.pool.map(_process_batch, ((bbox_pred_np[b], gt_boxes[b], gt_classes[b], dontcare[b], iou_pred_np[b]) for b in range(bsize)))\n",
    "\n",
    "        _boxes = np.stack(tuple((row[0] for row in targets)))\n",
    "        _ious = np.stack(tuple((row[1] for row in targets)))\n",
    "        _classes = np.stack(tuple((row[2] for row in targets)))\n",
    "        _box_mask = np.stack(tuple((row[3] for row in targets)))\n",
    "        _iou_mask = np.stack(tuple((row[4] for row in targets)))\n",
    "        _class_mask = np.stack(tuple((row[5] for row in targets)))\n",
    "\n",
    "        return _boxes, _ious, _classes, _box_mask, _iou_mask, _class_mask\n",
    "\n",
    "    def load_from_npz(self, fname, num_conv=None):\n",
    "        dest_src = {'conv.weight': 'kernel', 'conv.bias': 'biases',\n",
    "                    'bn.weight': 'gamma', 'bn.bias': 'biases',\n",
    "                    'bn.running_mean': 'moving_mean', 'bn.running_var': 'moving_variance'}\n",
    "        params = np.load(fname)\n",
    "        own_dict = self.state_dict()\n",
    "        keys = own_dict.keys()\n",
    "\n",
    "        for i, start in enumerate(range(0, len(keys), 5)):\n",
    "            if num_conv is not None and i>= num_conv:\n",
    "                break\n",
    "            end = min(start+5, len(keys))\n",
    "            for key in keys[start:end]:\n",
    "                list_key = key.split('.')\n",
    "                ptype = dest_src['{}.{}'.format(list_key[-2], list_key[-1])]\n",
    "                src_key = '{}-convolutional/{}:0'.format(i, ptype)\n",
    "                print(src_key, own_dict[key].size(), params[src_key].shape)\n",
    "                param = torch.from_numpy(params[src_key])\n",
    "                if ptype == 'kernel':\n",
    "                    param = param.permute(3, 2, 0, 1)\n",
    "                own_dict[key].copy_(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
