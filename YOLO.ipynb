{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %load darknet.py\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import utils.network as net_utils\n",
    "import cfgs.config as cfg\n",
    "from layers.reorg.reorg_layer import ReorgLayer\n",
    "from utils.cython_bbox import bbox_ious, bbox_intersections, bbox_overlaps, anchor_intersections\n",
    "from utils.cython_yolo import yolo_to_bbox\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def _make_layers(in_channels, net_cfg):\n",
    "    layers = []\n",
    "\n",
    "    if len(net_cfg) > 0 and isinstance(net_cfg[0], list):\n",
    "        for sub_cfg in net_cfg:\n",
    "            layer, in_channels = _make_layers(in_channels, sub_cfg)\n",
    "            layers.append(layer)\n",
    "    else:\n",
    "        for item in net_cfg:\n",
    "            if item == 'M':\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                out_channels, ksize = item\n",
    "                layers.append(net_utils.Conv2d_BatchNorm(in_channels, out_channels, ksize, same_padding=True))\n",
    "                # layers.append(net_utils.Conv2d(in_channels, out_channels, ksize, same_padding=True))\n",
    "                in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(*layers), in_channels\n",
    "\n",
    "\n",
    "def _process_batch(data):\n",
    "    W, H = cfg.out_size\n",
    "    inp_size = cfg.inp_size\n",
    "    out_size = cfg.out_size\n",
    "\n",
    "    bbox_pred_np, gt_boxes, gt_classes, dontcares, iou_pred_np = data\n",
    "\n",
    "    # net output\n",
    "    hw, num_anchors, _ = bbox_pred_np.shape\n",
    "\n",
    "    # gt\n",
    "    _classes = np.zeros([hw, num_anchors, cfg.num_classes], dtype=np.float)\n",
    "    _class_mask = np.zeros([hw, num_anchors, 1], dtype=np.float)\n",
    "\n",
    "    _ious = np.zeros([hw, num_anchors, 1], dtype=np.float)\n",
    "    _iou_mask = np.zeros([hw, num_anchors, 1], dtype=np.float)\n",
    "\n",
    "    _boxes = np.zeros([hw, num_anchors, 4], dtype=np.float)\n",
    "    _boxes[:, :, 0:2] = 0.5\n",
    "    _boxes[:, :, 2:4] = 1.0\n",
    "    _box_mask = np.zeros([hw, num_anchors, 1], dtype=np.float) + 0.01\n",
    "\n",
    "    # scale pred_bbox\n",
    "    anchors = np.ascontiguousarray(cfg.anchors, dtype=np.float)\n",
    "    bbox_pred_np = np.expand_dims(bbox_pred_np, 0)\n",
    "    bbox_np = yolo_to_bbox(\n",
    "        np.ascontiguousarray(bbox_pred_np, dtype=np.float),\n",
    "        anchors,\n",
    "        H, W)\n",
    "    bbox_np = bbox_np[0]  # bbox_np = (hw, num_anchors, (x1, y1, x2, y2))   range: 0 ~ 1\n",
    "    bbox_np[:, :, 0::2] *= float(inp_size[0])  # rescale x\n",
    "    bbox_np[:, :, 1::2] *= float(inp_size[1])  # rescale y\n",
    "\n",
    "    # gt_boxes_b = np.asarray(gt_boxes[b], dtype=np.float)\n",
    "    gt_boxes_b = np.asarray(gt_boxes, dtype=np.float)\n",
    "\n",
    "    # for each cell, compare predicted_bbox and gt_bbox\n",
    "    bbox_np_b = np.reshape(bbox_np, [-1, 4])\n",
    "    ious = bbox_ious(\n",
    "        np.ascontiguousarray(bbox_np_b, dtype=np.float),\n",
    "        np.ascontiguousarray(gt_boxes_b, dtype=np.float)\n",
    "    )\n",
    "    best_ious = np.max(ious, axis=1).reshape(_iou_mask.shape)\n",
    "    iou_penalty = 0 - iou_pred_np[best_ious < cfg.iou_thresh]\n",
    "    _iou_mask[best_ious <= cfg.iou_thresh] = cfg.noobject_scale * iou_penalty\n",
    "\n",
    "    # locate the cell of each gt_boxe\n",
    "    cell_w = float(inp_size[0]) / W\n",
    "    cell_h = float(inp_size[1]) / H\n",
    "    cx = (gt_boxes_b[:, 0] + gt_boxes_b[:, 2]) * 0.5 / cell_w\n",
    "    cy = (gt_boxes_b[:, 1] + gt_boxes_b[:, 3]) * 0.5 / cell_h\n",
    "    cell_inds = np.floor(cy) * W + np.floor(cx)\n",
    "    cell_inds = cell_inds.astype(np.int)\n",
    "\n",
    "    target_boxes = np.empty(gt_boxes_b.shape, dtype=np.float)\n",
    "    target_boxes[:, 0] = cx - np.floor(cx)  # cx\n",
    "    target_boxes[:, 1] = cy - np.floor(cy)  # cy\n",
    "    target_boxes[:, 2] = (gt_boxes_b[:, 2] - gt_boxes_b[:, 0]) / inp_size[0] * out_size[0]  # tw\n",
    "    target_boxes[:, 3] = (gt_boxes_b[:, 3] - gt_boxes_b[:, 1]) / inp_size[1] * out_size[1]  # th\n",
    "\n",
    "    # for each gt boxes, match the best anchor\n",
    "    gt_boxes_resize = np.copy(gt_boxes_b)\n",
    "    gt_boxes_resize[:, 0::2] *= (out_size[0] / float(inp_size[0]))\n",
    "    gt_boxes_resize[:, 1::2] *= (out_size[1] / float(inp_size[1]))\n",
    "    anchor_ious = anchor_intersections(\n",
    "        anchors,\n",
    "        np.ascontiguousarray(gt_boxes_resize, dtype=np.float)\n",
    "    )\n",
    "    anchor_inds = np.argmax(anchor_ious, axis=0)\n",
    "\n",
    "    ious_reshaped = np.reshape(ious, [hw, num_anchors, len(cell_inds)])\n",
    "    for i, cell_ind in enumerate(cell_inds):\n",
    "        if cell_ind >= hw or cell_ind < 0:\n",
    "            print cell_ind\n",
    "            continue\n",
    "        a = anchor_inds[i]\n",
    "\n",
    "        iou_pred_cell_anchor = iou_pred_np[cell_ind, a, :]  # 0 ~ 1, should be close to 1\n",
    "        _iou_mask[cell_ind, a, :] = cfg.object_scale * (1 - iou_pred_cell_anchor)\n",
    "        # _ious[cell_ind, a, :] = anchor_ious[a, i]\n",
    "        _ious[cell_ind, a, :] = ious_reshaped[cell_ind, a, i]\n",
    "\n",
    "        _box_mask[cell_ind, a, :] = cfg.coord_scale\n",
    "        target_boxes[i, 2:4] /= anchors[a]\n",
    "        _boxes[cell_ind, a, :] = target_boxes[i]\n",
    "\n",
    "        _class_mask[cell_ind, a, :] = cfg.class_scale\n",
    "        _classes[cell_ind, a, gt_classes[i]] = 1.\n",
    "\n",
    "    # _boxes[:, :, 2:4] = np.maximum(_boxes[:, :, 2:4], 0.001)\n",
    "    # _boxes[:, :, 2:4] = np.log(_boxes[:, :, 2:4])\n",
    "\n",
    "    return _boxes, _ious, _classes, _box_mask, _iou_mask, _class_mask\n",
    "\n",
    "\n",
    "class Darknet19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Darknet19, self).__init__()\n",
    "\n",
    "        net_cfgs = [\n",
    "            # conv1s\n",
    "            [(32, 3)],\n",
    "            ['M', (64, 3)],\n",
    "            ['M', (128, 3), (64, 1), (128, 3)],\n",
    "            ['M', (256, 3), (128, 1), (256, 3)],\n",
    "            ['M', (512, 3), (256, 1), (512, 3), (256, 1), (512, 3)],\n",
    "            # conv2\n",
    "            ['M', (1024, 3), (512, 1), (1024, 3), (512, 1), (1024, 3)],\n",
    "            # ------------\n",
    "            # conv3\n",
    "            [(1024, 3), (1024, 3)],\n",
    "            # conv4\n",
    "            [(1024, 3)]\n",
    "        ]\n",
    "\n",
    "        # darknet\n",
    "        self.conv1s, c1 = _make_layers(3, net_cfgs[0:5])\n",
    "        self.conv2, c2 = _make_layers(c1, net_cfgs[5])\n",
    "        # ---\n",
    "        self.conv3, c3 = _make_layers(c2, net_cfgs[6])\n",
    "\n",
    "        stride = 2\n",
    "        self.reorg = ReorgLayer(stride=2)   # stride*stride times the channels of conv1s\n",
    "        # cat [conv1s, conv3]\n",
    "        self.conv4, c4 = _make_layers((c1*(stride*stride) + c3), net_cfgs[7])\n",
    "\n",
    "        # linear\n",
    "        out_channels = cfg.num_anchors * (cfg.num_classes + 5)\n",
    "        self.conv5 = net_utils.Conv2d(c4, out_channels, 1, 1, relu=False)\n",
    "\n",
    "        # train\n",
    "        self.bbox_loss = None\n",
    "        self.iou_loss = None\n",
    "        self.cls_loss = None\n",
    "        self.pool = Pool(processes=10)\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.bbox_loss + self.iou_loss + self.cls_loss\n",
    "\n",
    "    def forward(self, im_data, gt_boxes=None, gt_classes=None, dontcare=None):\n",
    "        conv1s = self.conv1s(im_data)\n",
    "        conv2 = self.conv2(conv1s)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv1s_reorg = self.reorg(conv1s)\n",
    "        cat_1_3 = torch.cat([conv1s_reorg, conv3], 1)\n",
    "        conv4 = self.conv4(cat_1_3)\n",
    "        conv5 = self.conv5(conv4)   # batch_size, out_channels, h, w\n",
    "\n",
    "        # for detection\n",
    "        # bsize, c, h, w -> bsize, h, w, c -> bsize, h x w, num_anchors, 5+num_classes\n",
    "        bsize, _, h, w = conv5.size()\n",
    "        # assert bsize == 1, 'detection only support one image per batch'\n",
    "        conv5_reshaped = conv5.permute(0, 2, 3, 1).contiguous().view(bsize, -1, cfg.num_anchors, cfg.num_classes + 5)\n",
    "\n",
    "        # tx, ty, tw, th, to -> sig(tx), sig(ty), exp(tw), exp(th), sig(to)\n",
    "        xy_pred = F.sigmoid(conv5_reshaped[:, :, :, 0:2])\n",
    "        wh_pred = torch.exp(conv5_reshaped[:, :, :, 2:4])\n",
    "        bbox_pred = torch.cat([xy_pred, wh_pred], 3)\n",
    "        iou_pred = F.sigmoid(conv5_reshaped[:, :, :, 4:5])\n",
    "\n",
    "        score_pred = conv5_reshaped[:, :, :, 5:].contiguous()\n",
    "        prob_pred = F.softmax(score_pred.view(-1, score_pred.size()[-1])).view_as(score_pred)\n",
    "\n",
    "        # for training\n",
    "        if self.training:\n",
    "            bbox_pred_np = bbox_pred.data.cpu().numpy()\n",
    "            iou_pred_np = iou_pred.data.cpu().numpy()\n",
    "            _boxes, _ious, _classes, _box_mask, _iou_mask, _class_mask = self._build_target(\n",
    "                bbox_pred_np, gt_boxes, gt_classes, dontcare, iou_pred_np)\n",
    "\n",
    "            _boxes = net_utils.np_to_variable(_boxes)\n",
    "            _ious = net_utils.np_to_variable(_ious)\n",
    "            _classes = net_utils.np_to_variable(_classes)\n",
    "            box_mask = net_utils.np_to_variable(_box_mask, dtype=torch.FloatTensor)\n",
    "            iou_mask = net_utils.np_to_variable(_iou_mask, dtype=torch.FloatTensor)\n",
    "            class_mask = net_utils.np_to_variable(_class_mask, dtype=torch.FloatTensor)\n",
    "\n",
    "            num_boxes = sum((len(boxes) for boxes in gt_boxes))\n",
    "\n",
    "            # _boxes[:, :, :, 2:4] = torch.log(_boxes[:, :, :, 2:4])\n",
    "            box_mask = box_mask.expand_as(_boxes)\n",
    "\n",
    "            self.bbox_loss = nn.MSELoss(size_average=False)(bbox_pred * box_mask, _boxes * box_mask) / num_boxes\n",
    "            self.iou_loss = nn.MSELoss(size_average=False)(iou_pred * iou_mask, _ious * iou_mask) / num_boxes\n",
    "\n",
    "            class_mask = class_mask.expand_as(prob_pred)\n",
    "            self.cls_loss = nn.MSELoss(size_average=False)(prob_pred * class_mask, _classes * class_mask) / num_boxes\n",
    "\n",
    "        return bbox_pred, iou_pred, prob_pred\n",
    "\n",
    "    def _build_target(self, bbox_pred_np, gt_boxes, gt_classes, dontcare, iou_pred_np):\n",
    "        \"\"\"\n",
    "        :param bbox_pred: shape: (bsize, h x w, num_anchors, 4) : (sig(tx), sig(ty), exp(tw), exp(th))\n",
    "        \"\"\"\n",
    "\n",
    "        bsize = bbox_pred_np.shape[0]\n",
    "\n",
    "        targets = self.pool.map(_process_batch, ((bbox_pred_np[b], gt_boxes[b], gt_classes[b], dontcare[b], iou_pred_np[b]) for b in range(bsize)))\n",
    "\n",
    "        _boxes = np.stack(tuple((row[0] for row in targets)))\n",
    "        _ious = np.stack(tuple((row[1] for row in targets)))\n",
    "        _classes = np.stack(tuple((row[2] for row in targets)))\n",
    "        _box_mask = np.stack(tuple((row[3] for row in targets)))\n",
    "        _iou_mask = np.stack(tuple((row[4] for row in targets)))\n",
    "        _class_mask = np.stack(tuple((row[5] for row in targets)))\n",
    "\n",
    "        return _boxes, _ious, _classes, _box_mask, _iou_mask, _class_mask\n",
    "\n",
    "    def load_from_npz(self, fname, num_conv=None):\n",
    "        dest_src = {'conv.weight': 'kernel', 'conv.bias': 'biases',\n",
    "                    'bn.weight': 'gamma', 'bn.bias': 'biases',\n",
    "                    'bn.running_mean': 'moving_mean', 'bn.running_var': 'moving_variance'}\n",
    "        params = np.load(fname)\n",
    "        own_dict = self.state_dict()\n",
    "        keys = own_dict.keys()\n",
    "\n",
    "        for i, start in enumerate(range(0, len(keys), 5)):\n",
    "            if num_conv is not None and i>= num_conv:\n",
    "                break\n",
    "            end = min(start+5, len(keys))\n",
    "            for key in keys[start:end]:\n",
    "                list_key = key.split('.')\n",
    "                ptype = dest_src['{}.{}'.format(list_key[-2], list_key[-1])]\n",
    "                src_key = '{}-convolutional/{}:0'.format(i, ptype)\n",
    "                print(src_key, own_dict[key].size(), params[src_key].shape)\n",
    "                param = torch.from_numpy(params[src_key])\n",
    "                if ptype == 'kernel':\n",
    "                    param = param.permute(3, 2, 0, 1)\n",
    "                own_dict[key].copy_(param)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "VOCdevkit path does not exist: /home/trent/visual-recognition-traffic-signs/yolo2-pytorch/data/VOCdevkit2007",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9815d2604eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m imdb = VOCDataset(cfg.imdb_train, cfg.DATA_DIR, cfg.train_batch_size,\n\u001b[0;32m---> 25\u001b[0;31m                   yolo_utils.preprocess_train, processes=2, shuffle=True, dst_size=cfg.inp_size)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load data succ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/trent/visual-recognition-traffic-signs/yolo2-pytorch/datasets/pascal_voc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, imdb_name, datadir, batch_size, im_processor, processes, shuffle, dst_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devkit_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VOCdevkit{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devkit_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VOC{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devkit_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VOCdevkit path does not exist: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devkit_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Path does not exist: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: VOCdevkit path does not exist: /home/trent/visual-recognition-traffic-signs/yolo2-pytorch/data/VOCdevkit2007"
     ]
    }
   ],
   "source": [
    "# %load train.py\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import datetime\n",
    "from torch.multiprocessing import Pool\n",
    "\n",
    "from darknet import Darknet19\n",
    "\n",
    "from datasets.pascal_voc import VOCDataset\n",
    "import utils.yolo as yolo_utils\n",
    "import utils.network as net_utils\n",
    "from utils.timer import Timer\n",
    "import cfgs.config as cfg\n",
    "\n",
    "try:\n",
    "    from pycrayon import CrayonClient\n",
    "except ImportError:\n",
    "    CrayonClient = None\n",
    "\n",
    "\n",
    "# data loader\n",
    "imdb = VOCDataset(cfg.imdb_train, cfg.DATA_DIR, cfg.train_batch_size,\n",
    "                  yolo_utils.preprocess_train, processes=2, shuffle=True, dst_size=cfg.inp_size)\n",
    "print('load data succ...')\n",
    "\n",
    "net = Darknet19()\n",
    "# net_utils.load_net(cfg.trained_model, net)\n",
    "# pretrained_model = os.path.join(cfg.train_output_dir, 'darknet19_voc07trainval_exp1_63.h5')\n",
    "# pretrained_model = cfg.trained_model\n",
    "# net_utils.load_net(pretrained_model, net)\n",
    "net.load_from_npz(cfg.pretrained_model, num_conv=18)\n",
    "net.cuda()\n",
    "net.train()\n",
    "print('load net succ...')\n",
    "\n",
    "# optimizer\n",
    "start_epoch = 0\n",
    "lr = cfg.init_learning_rate\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)\n",
    "\n",
    "# tensorboad\n",
    "use_tensorboard = cfg.use_tensorboard and CrayonClient is not None\n",
    "# use_tensorboard = False\n",
    "remove_all_log = False\n",
    "if use_tensorboard:\n",
    "    cc = CrayonClient(hostname='127.0.0.1')\n",
    "    if remove_all_log:\n",
    "        print('remove all experiments')\n",
    "        cc.remove_all_experiments()\n",
    "    if start_epoch == 0:\n",
    "        try:\n",
    "            cc.remove_experiment(cfg.exp_name)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        exp = cc.create_experiment(cfg.exp_name)\n",
    "    else:\n",
    "        exp = cc.open_experiment(cfg.exp_name)\n",
    "\n",
    "batch_per_epoch = imdb.batch_per_epoch\n",
    "train_loss = 0\n",
    "bbox_loss, iou_loss, cls_loss = 0., 0., 0.\n",
    "cnt = 0\n",
    "t = Timer()\n",
    "step_cnt = 0\n",
    "for step in range(start_epoch * imdb.batch_per_epoch, cfg.max_epoch * imdb.batch_per_epoch):\n",
    "    t.tic()\n",
    "    # batch\n",
    "    batch = imdb.next_batch()\n",
    "    im = batch['images']\n",
    "    gt_boxes = batch['gt_boxes']\n",
    "    gt_classes = batch['gt_classes']\n",
    "    dontcare = batch['dontcare']\n",
    "    orgin_im = batch['origin_im']\n",
    "\n",
    "    # forward\n",
    "    im_data = net_utils.np_to_variable(im, is_cuda=True, volatile=False).permute(0, 3, 1, 2)\n",
    "    net(im_data, gt_boxes, gt_classes, dontcare)\n",
    "\n",
    "    # backward\n",
    "    loss = net.loss\n",
    "    bbox_loss += net.bbox_loss.data.cpu().numpy()[0]\n",
    "    iou_loss += net.iou_loss.data.cpu().numpy()[0]\n",
    "    cls_loss += net.cls_loss.data.cpu().numpy()[0]\n",
    "    train_loss += loss.data.cpu().numpy()[0]\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cnt += 1\n",
    "    step_cnt += 1\n",
    "    duration = t.toc()\n",
    "    if step % cfg.disp_interval == 0:\n",
    "        train_loss /= cnt\n",
    "        bbox_loss /= cnt\n",
    "        iou_loss /= cnt\n",
    "        cls_loss /= cnt\n",
    "        print('epoch %d[%d/%d], loss: %.3f, bbox_loss: %.3f, iou_loss: %.3f, cls_loss: %.3f (%.2f s/batch, rest:%s)' % (\n",
    "            imdb.epoch, step_cnt, batch_per_epoch, train_loss, bbox_loss, iou_loss, cls_loss, duration,\n",
    "            str(datetime.timedelta(seconds=int((batch_per_epoch - step_cnt) * duration)))))\n",
    "\n",
    "        if use_tensorboard and step % cfg.log_interval == 0:\n",
    "            exp.add_scalar_value('loss_train', train_loss, step=step)\n",
    "            exp.add_scalar_value('loss_bbox', bbox_loss, step=step)\n",
    "            exp.add_scalar_value('loss_iou', iou_loss, step=step)\n",
    "            exp.add_scalar_value('loss_cls', cls_loss, step=step)\n",
    "            exp.add_scalar_value('learning_rate', lr, step=step)\n",
    "\n",
    "        train_loss = 0\n",
    "        bbox_loss, iou_loss, cls_loss = 0., 0., 0.\n",
    "        cnt = 0\n",
    "        t.clear()\n",
    "\n",
    "    if step > 0 and (step % imdb.batch_per_epoch == 0):\n",
    "        if imdb.epoch in cfg.lr_decay_epochs:\n",
    "            lr *= cfg.lr_decay\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)\n",
    "\n",
    "        save_name = os.path.join(cfg.train_output_dir, '{}_{}.h5'.format(cfg.exp_name, imdb.epoch))\n",
    "        net_utils.save_net(save_name, net)\n",
    "        print('save model: {}'.format(save_name))\n",
    "        step_cnt = 0\n",
    "\n",
    "imdb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %load demo.py\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.multiprocessing import Pool\n",
    "\n",
    "from darknet import Darknet19\n",
    "import utils.yolo as yolo_utils\n",
    "import utils.network as net_utils\n",
    "from utils.timer import Timer\n",
    "import cfgs.config as cfg\n",
    "\n",
    "\n",
    "def preprocess(fname):\n",
    "    # return fname\n",
    "    image = cv2.imread(fname)\n",
    "    im_data = np.expand_dims(yolo_utils.preprocess_test((image, None, cfg.inp_size))[0], 0)\n",
    "    return image, im_data\n",
    "\n",
    "\n",
    "# hyper-parameters\n",
    "# npz_fname = 'models/yolo-voc.weights.npz'\n",
    "h5_fname = 'models/yolo-voc.weights.h5'\n",
    "trained_model = cfg.trained_model\n",
    "# trained_model = os.path.join(cfg.train_output_dir, 'darknet19_voc07trainval_exp3_158.h5')\n",
    "thresh = 0.5\n",
    "im_path = 'demo'\n",
    "# ---\n",
    "\n",
    "net = Darknet19()\n",
    "net_utils.load_net(trained_model, net)\n",
    "# net.load_from_npz(npz_fname)\n",
    "# net_utils.save_net(h5_fname, net)\n",
    "net.cuda()\n",
    "net.eval()\n",
    "print('load model succ...')# %load demo.py\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.multiprocessing import Pool\n",
    "\n",
    "from darknet import Darknet19\n",
    "import utils.yolo as yolo_utils\n",
    "import utils.network as net_utils\n",
    "from utils.timer import Timer\n",
    "import cfgs.config as cfg\n",
    "\n",
    "\n",
    "def preprocess(fname):\n",
    "    # return fname\n",
    "    image = cv2.imread(fname)\n",
    "    im_data = np.expand_dims(yolo_utils.preprocess_test((image, None, cfg.inp_size))[0], 0)\n",
    "    return image, im_data\n",
    "\n",
    "\n",
    "# hyper-parameters\n",
    "# npz_fname = 'models/yolo-voc.weights.npz'\n",
    "h5_fname = 'models/yolo-voc.weights.h5'\n",
    "trained_model = cfg.trained_model\n",
    "# trained_model = os.path.join(cfg.train_output_dir, 'darknet19_voc07trainval_exp3_158.h5')\n",
    "thresh = 0.5\n",
    "im_path = 'demo'\n",
    "# ---\n",
    "\n",
    "net = Darknet19()\n",
    "net_utils.load_net(trained_model, net)\n",
    "# net.load_from_npz(npz_fname)\n",
    "# net_utils.save_net(h5_fname, net)\n",
    "net.cuda()\n",
    "net.eval()\n",
    "print('load model succ...')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
